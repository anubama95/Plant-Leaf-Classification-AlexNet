{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import CSVLogger, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/home/asus/Desktop/Dataset_splits/train/\"\n",
    "test_dir = \"/home/asus/Desktop/Dataset_splits/validation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "early_stopper = EarlyStopping(min_delta=0.001, patience=10)\n",
    "csv_logger = CSVLogger('editalexnet_scratch_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nb_files(directory):\n",
    "    \"\"\"Get number of files by searching directory recursively\"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        return 0\n",
    "    cnt = 0\n",
    "    for r, dirs, files in os.walk(directory):\n",
    "        for dr in dirs:\n",
    "            cnt += len(glob.glob(os.path.join(r, dr + \"/*\")))\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "    plt.plot(epochs, acc, 'r.')\n",
    "    plt.plot(epochs, val_acc, 'r')\n",
    "    plt.title('Training and validation accuracy')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'r.')\n",
    "    plt.plot(epochs, val_loss, 'r-')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 25\n",
    "nb_train_samples = get_nb_files(train_dir)\n",
    "num_classes = len(glob.glob(train_dir + \"/*\"))\n",
    "nb_val_samples = get_nb_files(test_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "IM_WIDTH, IM_HEIGHT = 150, 150\n",
    "input_shape = (IM_WIDTH, IM_HEIGHT, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22110 images belonging to 33 classes.\n",
      "Found 4132 images belonging to 33 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(IM_WIDTH, IM_HEIGHT), batch_size=batch_size)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(IM_WIDTH, IM_HEIGHT), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (11, 11), input_shape=input_shape, padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size= (3, 3)))\n",
    "\n",
    "model.add(Conv2D(128, (7, 7), padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model.add(Convolution2D(192, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model.add(Convolution2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(12 * 12 * 256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(num_classes , activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 150, 150, 64)      23296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 150, 150, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 150, 150, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 50, 128)       401536    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50, 50, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 192)       221376    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 192)       768       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 5, 5, 256)         442624    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 36864)             9474048   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 36864)             147456    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              150999040 \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 33)                135201    \n",
      "=================================================================\n",
      "Total params: 161,863,521\n",
      "Trainable params: 161,780,321\n",
      "Non-trainable params: 83,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asus/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  after removing the cwd from sys.path.\n",
      "/home/asus/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., steps_per_epoch=172, validation_data=<keras.pre..., class_weight=\"auto\", callbacks=[<keras.ca..., epochs=25, validation_steps=32)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "172/172 [==============================] - 2460s 14s/step - loss: 1.4997 - accuracy: 0.5993 - val_loss: 3.6040 - val_accuracy: 0.1069\n",
      "Epoch 2/25\n",
      "172/172 [==============================] - 2422s 14s/step - loss: 0.7655 - accuracy: 0.7576 - val_loss: 1.7228 - val_accuracy: 0.5659\n",
      "Epoch 3/25\n",
      "172/172 [==============================] - 2393s 14s/step - loss: 0.5392 - accuracy: 0.8238 - val_loss: 1.1815 - val_accuracy: 0.6656\n",
      "Epoch 4/25\n",
      "172/172 [==============================] - 2614s 15s/step - loss: 0.4756 - accuracy: 0.8504 - val_loss: 0.8117 - val_accuracy: 0.7522\n",
      "Epoch 5/25\n",
      "172/172 [==============================] - 2374s 14s/step - loss: 0.3371 - accuracy: 0.8843 - val_loss: 0.6536 - val_accuracy: 0.8214\n",
      "Epoch 6/25\n",
      "172/172 [==============================] - 2500s 15s/step - loss: 0.3007 - accuracy: 0.9007 - val_loss: 0.4677 - val_accuracy: 0.8789\n",
      "Epoch 7/25\n",
      "172/172 [==============================] - 2381s 14s/step - loss: 0.2536 - accuracy: 0.9147 - val_loss: 0.8239 - val_accuracy: 0.8254\n",
      "Epoch 8/25\n",
      "172/172 [==============================] - 2527s 15s/step - loss: 0.2046 - accuracy: 0.9304 - val_loss: 0.6633 - val_accuracy: 0.8167\n",
      "Epoch 9/25\n",
      "172/172 [==============================] - 2395s 14s/step - loss: 0.1949 - accuracy: 0.9349 - val_loss: 0.5921 - val_accuracy: 0.8684\n",
      "Epoch 10/25\n",
      "172/172 [==============================] - 2557s 15s/step - loss: 0.1601 - accuracy: 0.9445 - val_loss: 0.5288 - val_accuracy: 0.8816\n",
      "Epoch 11/25\n",
      "172/172 [==============================] - 2394s 14s/step - loss: 0.1428 - accuracy: 0.9532 - val_loss: 0.3821 - val_accuracy: 0.8969\n",
      "Epoch 12/25\n",
      "172/172 [==============================] - 2491s 14s/step - loss: 0.1187 - accuracy: 0.9589 - val_loss: 0.3275 - val_accuracy: 0.8571\n",
      "Epoch 13/25\n",
      "172/172 [==============================] - 2427s 14s/step - loss: 0.1099 - accuracy: 0.9641 - val_loss: 0.6566 - val_accuracy: 0.8289\n",
      "Epoch 14/25\n",
      "172/172 [==============================] - 2371s 14s/step - loss: 0.0903 - accuracy: 0.9689 - val_loss: 0.5265 - val_accuracy: 0.8546\n",
      "Epoch 15/25\n",
      "172/172 [==============================] - 2489s 14s/step - loss: 0.0818 - accuracy: 0.9725 - val_loss: 0.4557 - val_accuracy: 0.8909\n",
      "Epoch 16/25\n",
      "172/172 [==============================] - 2489s 14s/step - loss: 0.0861 - accuracy: 0.9727 - val_loss: 0.2740 - val_accuracy: 0.8974\n",
      "Epoch 17/25\n",
      "172/172 [==============================] - 2481s 14s/step - loss: 0.0611 - accuracy: 0.9799 - val_loss: 0.5072 - val_accuracy: 0.8694\n",
      "Epoch 18/25\n",
      "172/172 [==============================] - 2419s 14s/step - loss: 0.0607 - accuracy: 0.9798 - val_loss: 0.3163 - val_accuracy: 0.8999\n",
      "Epoch 19/25\n",
      "172/172 [==============================] - 2572s 15s/step - loss: 0.0609 - accuracy: 0.9828 - val_loss: 0.3284 - val_accuracy: 0.8924\n",
      "Epoch 20/25\n",
      "172/172 [==============================] - 2367s 14s/step - loss: 0.0469 - accuracy: 0.9839 - val_loss: 0.5130 - val_accuracy: 0.8834\n",
      "Epoch 21/25\n",
      "172/172 [==============================] - 2400s 14s/step - loss: 0.0498 - accuracy: 0.9837 - val_loss: 0.2903 - val_accuracy: 0.8809\n",
      "Epoch 22/25\n",
      "172/172 [==============================] - 2480s 14s/step - loss: 0.0169 - accuracy: 0.9956 - val_loss: 0.3783 - val_accuracy: 0.9193\n",
      "Epoch 23/25\n",
      "172/172 [==============================] - 2367s 14s/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.6710 - val_accuracy: 0.9276\n",
      "Epoch 24/25\n",
      "172/172 [==============================] - 2366s 14s/step - loss: 0.0106 - accuracy: 0.9985 - val_loss: 0.1414 - val_accuracy: 0.9253\n",
      "Epoch 25/25\n",
      "172/172 [==============================] - 2367s 14s/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.4513 - val_accuracy: 0.9293\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_train = model.fit_generator(train_generator, nb_epoch=epochs, steps_per_epoch=nb_train_samples // batch_size,\n",
    "                                    validation_data=test_generator, nb_val_samples=nb_val_samples // batch_size,\n",
    "                                    class_weight='auto', callbacks=[lr_reducer, early_stopper, csv_logger])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('finalAlex_Net_scratch.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
